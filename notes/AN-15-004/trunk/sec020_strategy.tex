%%____________________________________________________________________________||
\section{Analysis strategy}
\label{sec:strategy}

\textbf{FIXME: We either want to modify the content or simply put the relevant information described here somewhere else} \\

\subsection{The analysis during Run~1}

While the analysis strategy has evolved significantly prior to and
during Run~1, certain design features have remained central to the RA1
analysis throughout the run. These features, along with some of the
more important recent developments, are outlined below.

{\bf Model-independent search for new physics:}

The analysis is designed to be sensitive to a range of beyond standard
model (BSM) physics scenarios with signatures that are characterised
by jets and significant \met in the final state. The search is one of
the original Reference Analyses (RAs) that formed the basis of the CMS
SUSY search program at the beginning of Run~1. The program was
designed to be inclusive, model-independent (as much as possible), and
topology-based. 

The current incarnation of the RA1 search still retains its generic,
inclusive nature. A binned signal region, defined by a set of
inclusive selection criteria, is employed to provide sensitivity to a
range of new physics models. By the end of Run~1, three discriminating
variables were used to categorise signal event candidates: \scalht,
\njet, and \nb. In the case of SUSY, this choice of variables provides
sensitivity to the direct pair-production of all flavours of squarks,
as well as pair-produced gluinos and their decays via, again, all
favours of squarks. The large dymamic range in \scalht provides
sensitivity to a large range of mass splittings between the parent
sparticle and the LSP.

{\bf Robust performance under Start-Up conditions:}

The search relies on the \alphat variable, which strongly suppresses
the dominant background of multijet production from QCD, while
maintaining acceptance to new physics signatures with genuine \met in
the final state. At the beginning of Run~1, the \alphat variable was
chosen because it was shown to be extremely effective at operating
under Start-Up conditions, when the beam conditions and detector
performance were poorly understood. For example, multijet
events with significant \met from jet mismeasurements due to
instrumental effects are penalised to lower values of \alphat, hence
the variable exhibits an intrinsic robustness against potential
sources of ``fake'' \met.

% Further, the analysis did not use directly the \met variables and
% relied instead solely on calorimeter-based jets (with relatively
% high thresholds of \Pt > 50\gev) to

While the Collaboration now has a deep understanding of the detector
performance under Run~1 conditions, the strategy we employ will still
be very relevant when exploring the new high-energy, high-luminosity
frontier expected in Run~2.

{\bf Inclusive trigger strategy with low thresholds:}

The trigger strategy has made use of the \alphat variable at the HLT
since 2011. Given the rejection power of \alphat for multijet events,
we employ this variable (crossed with \scalht) at the trigger level,
which allows to push to lower thresholds for a given trigger rate with
respect to other discriminating variables typically used in jets +
\met searches (\eg \met, \mht, etc). A suite of \scalht-\alphat cross
triggers allowed the RA1 search to push as low as $\scalht > 200\gev$
and (effectively) $\mht \gtrsim 100\gev$ at the trigger, and as low as
$\scalht > 200\gev$ and (effectively) $\mht \gtrssim 130\gev$ in the
signal region definition, with near-maximum signal efficiency at the
cost of $\sim25$~Hz (of which $\sim$15 was ``parked'').

{\bf Multijet-free signal region.}

As the analysis has evolved, the event selection has been tailored to
provide a multijet-free sample of signal event candidates. This is
achieved by applying a \scalht-dependent \alphat threshold, tuned to
suppress the multijet contribution to the sub-percent level with
respect to the total background counts per signal region bin. This is
extremely important for the lowest \scalht bins, which provide a
significant contribution to the overall sensitivity to compressed SUSY
or Dark Matter models.

{\bf Access to new physics via initial state radiation:}

The analysis acceptance to very compressed SUSY models relies not on
the detection of very soft objects (often failing acceptance cuts)
produced in the decay of the sparticles, but instead on the presence
of jets from initial state radiation. The signal acceptance times
efficiency for this mechanism is typically at the sub-percent level.
Further, the signal is characterised by a very broad shape in \scalht,
with significant counts at low \scalht, as well low values of \njet,
\nb, and \mht. Hence, the highest signal counts are typically found in
the bins with the highest background counts, typically populated by
events from W + jets and Z$\ra\nu\nu$ + jets, which results in a poor
S/B. Hence, the signal shape over many bins has to be considered in
order to achieve reasonable sensitivity to such signatures. One
distinguishing feature with respect to the SM backgrounds, which is
most pronounced for (near-)degenerate spectra, is that while the
values of \scalht and \mht are typically small, the ratio $\mht /
\scalht$ is large with respect to SM backgrounds.

This mechanism of signal acceptance was the focus of the ``parked
analysis'' in Ref~\cite{CMS_AN_2013-366}. While the interpretations of
this result focused on strongly-produced compressed SUSY models, the
same mechanism can be used to access the direct production of a Dark
Matter candidate, as detailed in Sec.~\ref{sec:dm}. Sensitivity to this
class of models relies heavily on tight background control and low
thresholds. This is the motivation for the strategies of developing
high-performance triggers with low thresholds, tuning the event
selection to provide a multijet-free signal region, and relying on a
large ensemble of closure tests in data to demonstrate excellent
control of the non-multijet backgrounds in the signal region.

{\bf Data-driven background estimation methods and closure tests:}

The analysis relies on multiple data control samples to predict the
non-multijet backgrounds. The control samples have a composition very
similar to the signal region, cover a very similar kinematic phase
space, have a large acceptance, and are signal-depleted. The analysis
relies on transfer factors constructed from MC to extrapolate from the
control regions to the signal region. The extrapolation is minimised
by using identical binning in all samples. Potential residual biases
in the transfer factors, \eg from MC mismodelling, are probed though a
large ensemble of closure tests performed between numerous data
control sub-samples. Several hundred statistically independent tests
are performed, which cover a wide range of potential biases. 

These closure tests are one of the most crucial components of this
analysis, as they provide an understanding of the reliance on MC (in
the form of ratios, \ie transfer factors) that is {\it founded on
  comparison with data}. Any potential biases or dependencies on the
discriminating variables used to categorise the signal events must be
understood prior to unblinding the signal region. There are concrete
examples in the past when the closure tests have revealed problems,
which had to be understood and solved prior to continuing with the
analysis.

In the absence of any significant biases, the closure tests are then
used to determine systematic uncertainties on the transfer factors,
which are propagated through to the analysis result via the likelihood
model. These systematic uncertainties are therefore motivated through
comparisons with control data and are, ultimately, statistically
limited by the data counts in the control samples. With increasing
integrated luminosity, we expect the closure tests to be increasingly
statistically-significant probes of potential biases and, in the
absence of bias, the systematic uncertainties will correspondingly
reduce.

\subsection{Developments with respect to the Run~1 analysis}
\label{sec:changes}

We plan to build on the experience gained during Run~1 and develop the
analysis to provide improved sensitivity to a range of new physics
models. These developments fall broadly under three categories:

\begin{itemize}
\item general optimisations concerning event reconstruction and
  selection;
\item improvements in the sensitivity to heavy objects, such as gluinos;
\item improvements concerning compressed SUSY and Dark Matter
  models. 
\end{itemize}

Some of these changes have already been implemented, while some are
still under study. The status will be noted at appropriate points in
this document. A summary of these changes are listed below. This list
is not exhaustive and some developments are subject to change.

{\bf Particle Flow event reconstruction:}

The analysis will switch from relying on jets reconstructed solely
from calorimeter information to the use of jets from the Particle Flow
(PF) reconstruction algorithm. This change will provide performance
improvements for jet-based variables (including \scalht, \mht, and
\alphat) and, in particular, better mitigate any effects relating to
pileup.

{\bf General event selection optimisation:}

In addition to the switch to PF, all event selection criteria for the
signal region and control samples are currently under review. The jet
\Pt threshold is no longer scaled at low \scalht as during Run~1, and
the binning in \scalht has been simplified. The binning choice in the
signal region will evolve with integrated luminosity.  We also plan to
investigate developments concerning lepton isolation and boosted
objects.

{\bf Trigger strategy:}

The trigger strategy is similar to that of Run~1, which will continue
to rely on a suite of \scalht-\alphat cross triggers at the HLT. The
trigger decision is now based on PF jets, rather than
calorimeter-based jets as during Run~1. The aim is to maintain the
thresholds used at the end of Run~1, which fall in the range of $200 <
\scalht < 400\gev$ and $0.57 > \alphat > 0.51$. MC-based studies have
revealed this appears to be achievable. Studies are ongoing to further
mitigate any performance degradation due to pileup.

The highest \scalht bins in the analysis will be seeded by the lowest
unprescaled \scalht trigger, which currently has a threshold of
$\scalht > 900\gev$.

There have also been developments of novel L1 seeds to improve
efficiencies at low \scalht. Studies suggest that the performance of
L1 cross triggers based on these seeds is sufficient to provide near
100\% efficiency down to $\scalht > 200\gev$.

{\bf \scalht-dependent \alphat thresholds:}

During Run-1, the \alphat thresholds were raised as high as $\alphat >
0.65$ for the lowest \scalht bins to suppress potential contamination
from multijet events to the sub-percent level with respect to the
total background counts. A constant threshold of $\alphat > 0.55$ was
used for all bins satisfying $\scalht > 325\gev$. However, \alphat is
a relative quantity that relates \scalht and \mht (and \dht) such that
there is an effective lower bound on \mht that increases linearly with
\scalht. In order to maximise signal acceptance, while maintaining at
least the same level of multijet rejection as in the lowest \scalht
bins, the \alphat threshold will be lowered as a function of \scalht
in line with the thresholds for the suite of HLT triggers. This
approach should allow an \alphat threshold as low as 0.52 for the
region $\scalht > 500\gev$, which corresponds to a lower bound on \mht
of $\sim130\gev$. This requirement on \mht is (indirectly) imposed on
all bins in the low \scalht region through an appropriate choice of
\alphat threshold.

For the region $\scalht > 900\gev$, events will be collected with the
lowest unpreascaled \scalht trigger in the HLT menu. As there is no
\alphat requirement in the trigger, we choose to employ a loose
baseline requirement of $\mht > 130\gev$ in place of \alphat (which
would correpond to a threshold of $\sim0.507$). While the use of
\alphat is necessary to push to low values of \scalht and \mht, we opt
for the \mht requirement at high \scalht as this provides a higher
signal efficiency than \alphat, while still controlling multijet
events. Any potential multijet contamination can be controlled through
other means, such as $\Delta\Phi^{*}_{\rm min}$.

This dependence on \scalht of the \alphat thresholds allows to open up
phase space, particularly to ``jetty'' signatures which are a
characteristic of gluino pair-production and decay. The approach
allows to maintain an approximately constant \mht requirement of
$\sim130\gev$ through the full range of $\scalht > 200\gev$.

{\bf Additional discriminating variables:}

During Run~1, events in the signal region were categorised according
to three discriminating variables: \scalht, \njet, and \nb. While
\scalht has historically been used in many searches for new physics at
the LHC as an estimator for the mass scale of new physics, another
characteristic signature for (R-parity conserving) SUSY and other
models involving the direct production of a Dark Matter candidate is
the presence of significant \met.

We are currently investigating options for an additional
discriminating variable that will improve the analysis sensitivity to
both the strong production of heavy objects such as gluinos and
squarks as well as compressed SUSY models and Dark Matter
candidates. The use of more than one discriminating variable, with
each potentially being used in different categories of the signal
region, is also being considered. Early candidates include \mht,
$M_{\rm eff}$, and variants.

{\bf Additional \njet categories:}

We will adopt a more granular jet multiplicity binning in Run~2, in
which events will be categorised according to whether they contain
exactly two, three, four, or at least five jets. This compares with
the two categories of $\njet = 2-3$ and $\njet \geq 4$ used during
Run~1. Events are also categorised according to the number of jets
that are tagged as originating from b-quarks, with up to as many as
four b-tags (as during Run~1). This finer granularity in the number of
jets helps to improve the sensitivity to a wide range of models,
including compressed SUSY scenarios, direct production of Dark Matter,
and gluino-mediated models.

{\bf ``Asymmetric'' jet \Pt thresholds:}

The nominal event selection criteria for the signal region include a
raised threshold of $100\gev$ for the two hardest jets in the
event. This raised threshold is aimed at reducing the V + jets
backgrounds while maintaining acceptance to SUSY models due to the
assumed pair-production of sparticles. (The decay of each
sparticle is assume to result in at least one hard jet.) 

However, for compressed SUSY and Dark Matter models, signal acceptance
is largely due to the presence of jets from initial state
radiation. Under this scenario, it is beneficial to relax the
requirements on the second leading jet in the event in order to
maximise acceptance. Hence, in addition to each ``nominal'' \njet
category, there is now a new disjoint ``asymmetric'' \njet category
that still requires a hard leading jet but also requires a soft second
jet. The ``asymmetric'' dijet category is therefore comparable to the
dijet bin of the monojet analysis~\cite{Chatrchyan:2011nd,
Chatrchyan:2012me, Khachatryan:2014rra}. Given that a minimum of two
jets are still required, the method of using \alphat to suppress
multijet contaimination is still applicable.

{\bf Additional data control samples:}

We are investigating the addition of new data control samples,
specifically an electron + jets and di-electron + jets sample. These
two samples will closely mirror their $\mu$ + jets and $\mu\mu$ + jets
counterparts. 

Further, as a baseline, we plan to mirror the \scalht-dependent
\alphat thresholds of the signal region in the $\gamma$ + jets
sample. We will also investigate the impact of removing entirely the
\alphat requirement. 

The overall aim is to maximise the data counts in multiple control
samples to allow better control of the extrapolations made in the
analysis. For example, the additional control samples will help reduce
the statistical uncertainties associated with the predictions in the
signal region.

{\bf Developments concerning closure tests:}

As in Run~1, closure tests will be performed in bins of \njet and
\scalht. These tests will allow to identify any biases or dependencies
in the predictions. If an additional discriminating variable is used
to categorise events in the signal region, we will investigate the
possibility to perform closure tests in slices of this variable.

The addition of two new electron control samples will allow many
additional closure tests to be performed, which will further improve
the understanding of the transfer factors constructed from MC, with
the ultimate aim of reducing their associated systematic
uncertainties.

%%____________________________________________________________________________||
