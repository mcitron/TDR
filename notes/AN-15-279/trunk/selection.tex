\section{Trigger \& Selection}
\label{selection}

\subsection{Trigger}


The RA1 analysis uses a wide range of triggers to maximise sensitivity to a range of signal topologies. 

We are using fived decited  $\scalht$-$\alphat$ cross-triggers with a requirement on the average \pt of the leading two jets, $\pt^{\rm \left<j1,j2\right>}$.The dijet average threshold provides an improved suppression of QCD multijet events within the trigger and therefore enabling looser \alphat thresholds to be utilised whilst maintaining acceptance to events exhibiting asymmetric jet topologies. A dijet average threshold of 90 \GeV ensured the optimum performance when balancing efficiency and rate, with both the $\scalht$ and $\alphat$ thresholds across all jet toplogies.  Events in the hadronic monojet signal region are selected using a single \mht-\met cross-trigger. The hadronic multijet signal region is selected by a suite of $\scalht$-$\alphat$ cross-triggers  

The $\scalht$-$\alphat$ triggers seed all signal multijet offline bins in the range for $\scalht > 200$ \GeV. Above $\scalht > 800$ an additional pure \scalht trigger is also utilised which has no explicit dependence on $\alphat$ or dijet average threshold. 

The analysis selection are defined to operate on or close to the trigger plateaus. Further Trigger weights are measured and applied as appropriate. Details regarding trigger efficiencies and turn-on curves can be found in Ref.~\cite{alphaTnote}.


Control regions ni hadronic, electron-, muon- and photon plus jet final states are selected. For the hadronic region prescaled $\scalht$ triggers, and a prescaled  $\scalht$-$\alphat$ cross-trigger, are utilised. These triggers share the same Level-1 seeds and $\scalht$ threshold of the signal cross-triggers and are similarly each mapped to a unique offline bin. The efficiency of these triggers are measured from an electron reference trigger in addition to an independent measurement with the \verb!HLT_Physics! 
minimum bias trigger.

The non-hadronic control regions are seeded by the lowest-threshold unprescaled triggers available in the given run scenario. The \mj and \mmj control samples are selected with the \verb!HLT_IsoMu20! trigger, and the \gj control sample by the \verb!HLT_Photon175! trigger. 


\subsection{Object Defintions}

We will give here a short overview of the objects definitions used and refer to ~\cite{alphaTnote} for details. All selection are based on POG recommended object definitions and correction factors are applied as provided by the POGs.

\begin{itemize}
  \item{\bf Jets}: This analysis uses particle-flow (PF) candidates clustered by the anti-$k_{T}$ jet clustering algorithm \cite{Cacciari:2008gp} using a cone radius of 0.4. The ``loose'' working point jet-ID selection is used. All recommended corrections and cleaning procedures are applied.   %  like charged hadron subtraction and jet energy are applied. 
    
  \item{\bf $b$-quarks:} The  ``medium'' working point of the 'Combined Secondary Vertex tagger V2' $b$-jet identification algorithm is used. This results in a light-quark mis-tag rate of $\sim$1 \%  and a $b$-tag signal efficiency of about 80 \%.   

  \item{\bf Muons} Muons are identified according to the ``medium'' working point definition of the recommended identification algorithm, which provides $\sim$ 98 $\%$ efficiency. 
Muons are also required to be isolated, i.e. with a low activity in the vicinity of their track. In the hadronic signal region, a PF-based relative isolation is used with a variable cone size, which is referred to as ``mini-isolation''. 

  \item{\bf Photons} Photons that are identified by the cut-based photon identification algorithm \cite{photon-id} and that fulfill the ``tight'' working point ($\sim$ 71 $\%$ efficiency) are used. The and required to be well isolated.  A PF-based isolation is used with a cone size $\Delta R$ $<$ 0.3  and correction to remove pile up effects are applied.


  \item{\bf Electrons} Isolated electrons are identified according to the ``loose'' working point definition ($\sim$ 90 $\%$ efficiency)  of the cut-based identification \cite{electron-id} for the purpose of the electron veto in the signal region, while the ``tight'' working point ($\sim$ 70 $\%$ efficiency) is used for the selection of electron in the corresponding control regions. Similarly to muons a PF-based isolation \cite{pf-photon} is used in the hadronic signal regions with a cone size determined by the mini isolation algorithm and corrections are applied to remove the effects of pileup.

  \item{\bf Isolated Tracks}  A single isolated track (SIT) can be used to identify leptonically decaysing $W$ bosons through their leptonic decays and single prong tau decays.
    A SIT comprises a charged PF candidate with $\Pt > 10 \gev$, $\Delta z(\mathrm{track}, \mathrm{PV}) < 0.05 \, \mathrm{cm}$  and with a relative isolation smaller than 0.1, where the isolation is determined from the sum of the \Pt of the charged PF candidates within $\Delta R < 0.3$.

 \item{\bf Missing transverse momentum} Missing transverse momentum (\met) is defined as the opposite of the vector sum of the transverse momentum of all particle-flow candidates in the event. Type-I \met correction \cite{Khachatryan:2014gga} are applied.


\end{itemize}


Muon, Electrons, Photons aren taus are vetoed in the definition of the hadronic signal region. Additional details of object selections and correction are described in Ref.~\cite{alphaTnote}

\subsection{Selections}


This section outlines the set of ``pre-selection'' requirements common to all signal and control regions, before defining the selection criteria that are specific to each region. 


All ``MET filters'' recommended by the JetMET POG and SUSY POG are applied to remove beam- and detector-related effects. Jets are required to satisfy $\PT>40\gev$ and $|\eta|<3.0$. Events containing jets in the forward region that satisfy the requirements $\PT>40\gev$ and $|\eta|>3.0$ are rejected in order to control background contributions from SM processes, without introducing a significant reduction in signal acceptance. 

The jets that are selected are used in the calculation of all jet-based event-level variables, such as \HT, \mht, and \alphat.

We require the leading jet to fullfill $\PT > 100\gev$ and $|\eta|<2.5$.  Events are then classified based on the second leading (trailing) jet. 
If the trailing jets satisfies $\PT > 100\gev$  events are assigned to a ``symmetric'' \njet category. If the second
jet satisfies $40 < \PT < 100\gev$ events are assigned to an ``asymmetric'' \njet category. Finally, if there is no second leading
jet with $\PT>40\gev$, events are assigned to the ``mono-jet'' category. 


The baseline selection ('preselection') requires events have significant hadronic activity by requiring $\scalht > 200\GeV$.  Events in all samples are binned identically, according to the \HT variable. The choice of binning in \HT is driven primarily by the trigger strategy: 50\gev
bins in the range $200 < \HT < 400\gev$, 100\gev bins in the range $400 < \HT < 600\gev$, a 200\gev bin $600<\HT<800\gev$ and a final 
inclusive bin $\HT > 800\gev$. The resulting sub-samples comprise events containing exactly one, two, three, four, or at least five jets. These are further split into the aforementioned  ``monojet'',  ``symmetric'' or ``asymmetric'' \njet categories. Events are as well categorised according to the the number of b-tagged jets (``b-jets''), by requiring exactly zero, one, two, or at least three b-tagged jets. 


Events in the 'mono-jet' category and control regions that don't apply an \alphat selection have to fulfill $\mht>130\gev$ to ensures that all events used in the analysis have a comparable missing energy similar as introduced in the signal regions with \alphat cut. An overview of all selection criteria is given in Table~\ref{tab:pre-selections}.


Expanding the analysis to consider a wide variety of DM final states has been the main focus for Run I. This results in the addition of two more jet categories, the monojet and asymmetric jet categories, that more than doubled the available signal regions. Because many DM signatures are ISR induced this included challenging soft kinematic regions. Events in the hadronic signal and all control regions are categorised identically and according to the number of jets (\njet) reconstructed in each event and the number of jets identified as originating from bottom quarks (\nb) in each event. 


\begin{table}[h!]
  \topcaption{Summary of the pre-selection criteria.}
  \label{tab:pre-selections}
  \centering
  \footnotesize
  \begin{tabular}{ ll }
    \hline
    \hline
    Selection                     & Requirement                                                                          \\
    \hline
    ``MET filters''               & Primary Vertex, CSC Beam Halo, HBHE Noise and Isolation, ECAL Endcap SC Noise        \\
    Jet acceptance                & $\PT > 40\gev$, $|\eta| < 3$                                                         \\
%    \njet                         & $\geq2$                                                                \\
    Lead jet acceptance           & $\PT > 100\gev$, $|\eta| <    2.5$                                     \\
    Second jet acceptance         & $\PT > 100\gev$ \testrm{or} $40 < \PT < 100\gev$                       \\
    Loosest \HT requirement       & $\HT > 200\gev$                                                        \\
    Loosest \mht requirement      & $>130\gev$                                                     \\  
    Baseline \HT binning          & 200--250, 250--300, 300--350, 350--400, 400--500, 500--600, 600--800, $>$800\gev \\
    Baseline \njet multiplicities & 1 (mono-jet), 2, 3, 4, $\geq$5 (both symmetric and asymmetric)                       \\
    Baseline \nb multiplicities   & 0, 1, 2, $\geq3$ ($\nb \leq \njet$)                                    \\
    \hline
    \hline
  \end{tabular}
\end{table}








%marcelle
\subsection{The signal region}

The hadronic signal regions is selected by rejecting events with an isolated electron with $\pt > 10\GeV$ and $|\eta| < 2.5$ or an isolated muon with $\pt > 10\GeV$ and $|\eta| < 2.5$. To furhter reduce backgrounds from \wj and \ttbar due to mis-reconstructed leptons, events with single isolated tracks with $\pt > 10\GeV$ and $|\eta| < 2.5$ are vetoed. In the case of the single and di-lepton control samples we do not veto events due to the presence of a track from the well identified leptons, by requiring $\Delta R(\textrm{track},\textrm{lepton}) > 0.02$. Finally, to select a purely hadronic topology and to allow for a orthogonal control region, events with an isolated photon with $\pt > 25\GeV$ and $|\eta| < 2.5$ are rejected.


The further selection is based on two powerful variables to discriminate instrumental and multijet background. These are the \alphat and \bdphi variables.

\subsubsection*{\alphat}

The \alphat dependence of \HT is used to adjust the \alphat requirement such that \mht is roughly constant across all \HT bins.  These are typically $\sim110 < \mht < \sim160\gev$. This approximate levelling of the ``effective'' \mht threshold implies increasingly tighter requirements against instrumental effects versus \HT, while maximising signal acceptance.  Table~\ref{tab:alphat-thresholds} shows the expected \alphat thresholds and corresponding ``effective'' \mht thresholds for each \HT bin. 
The \alphat threshold is dependent only on \HT and not on \njet nor \nb that are used to define the event categories.


\begin{table}[h!]
  \caption{\alphat and corresponding ``effective'' \mht (GeV) thresholds versus
    lower bound of \scalht bin. For all \HT bins satisfying $\HT > 800
    \gev$, the direct requirement of $\mht > 130\gev$ is imposed rather
    than a requirement on \alphat. No \alphat requirement is imposed in the
    monojet bins.}
  \label{tab:alphat-thresholds}
  \centering
  \footnotesize
  \begin{tabular}{ lcccccccc }
    \hline
    \hline
    \scalht            & 200       & 250       & 300       & 350       & 400       & 500       & 600       \\
    \hline                                                                                     
    \alphat threshold  & 0.65      & 0.60      & 0.55      & 0.53      & 0.52      & 0.52      & 0.52      \\
    ``Effective'' \mht & $\sim$128 & $\sim$138 & $\sim$125 & $\sim$123 & $\sim$110 & $\sim$138 & $\sim$162 \\
    \hline
    \hline
  \end{tabular}
\end{table}

All events satisfying $\HT > 800\gev$ are seeded by the single-object \texttt{HLT\_HT800} trigger, which is expected to be unprescaled. For these high \HT bins, no \alphat threshold is required, which removes the inefficiencies of this variable for high jet multiplicity events. Instead, the following $\mht >130\gev$ requirement helps to control the multijet background along with the imposition of $\bdphi > 0.5$.



\subsubsection*{\bdphi}

Further, an additional powerful variable \bdphi is used to suppress multijet contamination due to both instrumental effects and semi-leptonic heavy-flavour decays with genuine \met in the final state. The variable is determined as follows. The jet-based estimate of the missing transverse energy, ${\mhtvec}$, is recomputed while ignoring one of the reconstructed jets (the ``test'' jet). The
difference in the azimuthal angle between the recomputed $\mhtvec$ and the ``test'' jet is then determined. This process is repeated for each jet in the event and the minimum of all the azimuthal differences, \bdphi, is determined. For monojet events, the calculation is 
performed using all jets with $\Pt > 20\gev$. The ``test'' jet whose subtraction from the calculation $\mhtvec$ yields this minimum value, is
identified as the jet that is most likely to have given rise to the missing transverse energy in the event. Events with significant \mht
due to instrumental effects or heavy flavour decays populate the region $\bdphi \approx 0$ and so candidate signal event are accepted
only if they satisfy $\bdphi > 0.5$. The use of the \bdphi and \alphat variables provide an extremely powerful rejection factor against
contamination from multijet events and allow to maintain low jet \PT, \HT, and \mht thresholds, which in turn maximises signal acceptance
for a large range of DM and SUSY models with final states characterised by the presence of significant \met.


\subsubsection*{Cleanup selections}
To protect against multiple jets failing the $\Et$ threshold or falling out of detector acceptance, the jet-based estimate of the missing transverse energy, \mht, is compared to the missing transverse energy variable, $\met$, and events with $R_{\rm
  miss}=\mht/\met > 1.25$ are rejected. 
  
Masked regions in the ECAL (which amount to about 1\% of the ECAL channel count) or HCAL, or by missing instrumentation in the barrel-endcap gap, could cause severe energy losses. A data-driven method is developed to identify dead cells. The procedure is outlined in 
Ref.~\cite{alphaTnote}.
% The procedure is carried out on events that pass a loose selection of one good primary vertex,
%$\njet>1$ and $\scalht>150\gev$. For each identified jet with $\PT > 20 \gev$ in data, the azimuthal angle ($\Delta\phi_{jet}$) between the jet and the 
%recomputed ${\mhtvec}$ is determined, in the same way as in the procedure to compute the \bdphi 
%variable. The positions of all jets which give $\bdphi < 0.3$ are plotted in an $\eta-\phi$ map. Subsequently, the positions of all jets with
%$\pt>20\gev$ are plotted in a second $\eta-\phi$ map. These two maps are then divided to form a 2D ratio map, taking the
%first map as the numerator and second as the denominator. Jets pointing to dead cells are likely to give $\bdphi < 0.3$, so the
%location of dead cells in $\eta$ and $\phi$ have higher values in this 2D ratio map. Fig
The CSC beam halo filter has been found to be less efficient during the early Run 2 data-taking period compared to the previous run.
Beam halo events manifest themselves as single energy deposits in the calorimeters, which introduces large amounts of ``fake'' \met. This effect is especially prominent in the signal region monojet category, particularly at $\phi$ coordinates of 0 and $\pi$ because of the tendency of halo particles to lie within the plane of the LHC ring.  Such spurious events are suppressed by requiring at least 10\% of the leading jet's energy to originate from charged hadrons, $CHF>0.1$.  



The requirements that define the hadronic signal region are summarised in Table~\ref{tab:sr-selections}.

\begin{table}[h!]
  \topcaption{Summary of the signal region selection criteria, applied
    in addition to the pre-selection summarised in
    Table~\ref{tab:pre-selections}.}
  \label{tab:sr-selections}
  \centering
  \footnotesize
  \begin{tabular}{ ll }
    \hline
    \hline
    Selection             & Requirement                                                    \\
    \hline
    \alphat               & $>$0.52--0.65 (\HT-dependent) for region $200 < \HT < 800\gev$ \\
    \bdphi                & $>0.5$                                                         \\
    \mht/\met             & $<1.25$                                                        \\
    ``Dead ECAL filter''  & (see text)                                                     \\
    ``Beam Halo Filter''  &  $CHF(\textrm{leading jet})>0.1$                                \\

    \hline
    \hline
  \end{tabular}
\end{table}




\subsection{The \texorpdfstring{\mht}{MHT} discriminator }

As described above, and as used in Run~1, the analysis takes advantage of three discriminating variables, \njet, \nb, and \HT, to provide
sensitivity to a large range of SUSY (and DM) models. No extrapolation in these variables is performed, with predictions of SM background
yields in the (\njet,\nb,\HT) bins of the signal region based on both observed counts and transfer factors derived from simulated yields in
the corresponding (\njet,\nb,\HT) bins of the control samples. Each prediction is statistically and systematically independent.

In Run~1, for each (\njet,\nb,\HT) bin in the signal region, an extrapolation in the variable \alphat was necessary to obtain
background predictions based on the muon control samples, which did not impose any \alphat requirement. No extrapolation in \alphat was
performed for the photon control sample, which used the same \alphat requirements as the signal region. The \alphat requirements used in
Run~1 for the signal region correspond loosely to \mht thresholds in the range $\sim$130 to $\sim$500\gev depending on the \HT
bin. Uncertainties in this extrapolation were determined through closure tests with respect to data, including one dedicated to the
\alphat extrapolation, plus additional cross checks.

In Run~2, we additionally bin event counts in the signal region according to the variable \mht in order to provide further
discriminating power between any potential signal and the SM background counts. Hence, while no extrapolation is performed in
\njet, \nb, nor \HT, the analysis relies on information obtained from simulation to extrapolate from counts (integrated over \mht) in
the control samples to a predicted distribution in \mht for each corresponding (\njet,\nb,\HT) bin in the signal region.

The \mht dimension is included in the likelihood model using templates determined per (\njet,\nb,\HT) bin from simulation. An associated
normalisation nuisance is determined from closure tests between simulation and data, as described in
Sec.~\ref{sec:systematics}. Alternative templates are used to encode the systematic uncertainty in the \mht distribution obtained from
simulation. 

The templates use \mht bins of 50\gev in width. A metric is used to determine the threshold of the final \mht bin used by the
templates. This metric is currently based on requiring a minimum number of both observed counts in the {\it data control samples} and
(unweighted) simulated events with \mht values higher than the final bin threshold. While the counts in the (\njet~,\nb~,\HT) bins of each
data control sample are not binned according to \mht (as in the signal region), the former requirement ensures that there are
sufficient events in each (\njet~,\nb~,\HT) bin of the control samples to probe for potential systematic effects {\it across all bins in
  \mht} using closure tests between simulation and data, as described in Sec.~\ref{sec:systematics}. Hence, a data-driven validation for
potential biases on the systematic uncertainty in the \mht template is possible. The latter requirement minimises the statistical
uncertainties associated with the finite number of simulated events for the various SM background processes. Both requirement are based on
counts according to \njet and \nb but inclusive with respect to \nb.
